## Renaming

NetmikoDataExtractionService -> NetmikoRegexExtractionService

## Changes to the custom services

Before, eNMS was creating the custom form by looking at the properties of the custom service model.
Now, each time you create a custom service, you'll need to create a "Custom form" too.
The idea is the decouple the service model (what's stored in the database) from the form (UI only).
This change is not backward compatible and for all existing custom services, you will need to create a custom form.

Having a custom form along with the custom service model makes sense for many reasons:
- The order in which properties are displayed in the form now longer depends on the order in which properties are defined in the model.
- You can now set default values for your form.
- You will no longer use "property_values = ..." and "property_length = ..." and "property_textarea = ...".
The values of a list, maximum length of a string, and whether or not a text field is a "textarea" is controlled from the form, as it should have been from the beginning.

The following problems will be fixed by this change:
- Marc reportd the default value was ignored for the "textarea" fields: now it's working.
- You can define complex validation mechanism. WTforms provides you with a number of "validators" (https://wtforms.readthedocs.io/en/stable/validators.html)
to check that the user input is an email address, IP address, etc.
But if you need something more complex, you can define your own "validation function" to compute whether or not the form is valid based on user inputs:
see here for custom validators: https://wtforms.readthedocs.io/en/stable/validators.html#custom-validators

## New services

- TextFSM service: uses Netmiko to connect to a device, extract variables from the result with a TextFSM template.
- Python Snippet Service implemented by Marc now included by default.


## New Workflow system

Two modes:
- "Use workflow targets"
- "Use service targets"

In "Use service targets" mode, jobs run on their own targets. A job is considered successful
if it ran successfully on all of its targets (if it fails at least one target, it failed).
The "Use service targets" mode must be used for specific workflows where services have different targets.
For example, a first service would run on devices A, B, C and the next one on devices D, E.

In "Use workflow targets" mode, the workflow will run on its own targets (devices configured at service level
are ignored). Devices are independent from each other: one device may run on all jobs in the workflow
if it is successful while another one could stop at the first step: they run the workflow independently and
will likely follow different path in the workflow depending on whether they fail or pass services thoughout the workflow.

## Panel instead of Bootstrap modals

I am now using panels everywhere instead of modals.
Modals are blocking, which prevents from displaying two object modals of the same window
at the same time (for example, to compare device/service/workflow properties...).
Panels are more flexible, you can change the size, "dock" them, and minimize them.

## Filtering system

The table filtering system no longer uses inputs above table headers.
There are several reasons for this change:

- less resource-intensive for the server, a search is only triggered when the filter button is pressed, and not
everytime a key is pressed like before.

- possibility the search with criteria even if they are not table properties:
* filter by pools for links/device/configuration...
* filter by OS in the configuration table, even though OS is not a property of the configuration table
* filter by configuration in the device table, even though configuration is not a property of the device table, ETC ETC..)

- right now, you cannot choose whether you filter by "equality" (A == B), "inclusion" (A in B), or regex; it's only inclusion.
Eventually, I want to add equality AND regex for all properties in this filter window... similarly to what already exists for pools, but for table filtering.

- in the view, you can now filter links and devices with those table.
That means filter the view per device pools, configuration, model, OS, link subtype, pools etc...
That wasn't possible before.

- this was messing up with the alignment of the table headers (bug you've already reported).

## String lengths

- Instead of having all string length to 255, there are now two string length: 255 and 2 ** 10.
These lengths are default values, you can change them by setting the env variables:
"SMALL_STRING_LENGTH" and "LARGE_STRING_LENGTH".
The large string length is used where it makes sense (content match, etc).

## Dependencies

- Added Webassets: before, all javascript dependencies were served independently, which means a lot
of calls to the server were made to retrieve them.
Now all dependencies are automatically bundled in a single js file.
- Removed Flask-SQLalchemy. Was obfuscatign the way SQLalchemy works (wrt session management in particular),
now we use SQLalchemy directly.

## NSOT vs eNMS

We discussed one of the things NSOT was doing compared to eNMS was:
"a)  NSOT keeps a well defined changelog for each device.
This serves as a record in the case that an inventory change causes a device to fail, etc"
There is a now a changelog in eNMS too.
Each time you create, update or delete anything, a log is created.
If it is an update, eNMS tells you exactly which fields were updated (old and new values),
when, and by whom.

## Switch from Multithreading to Multiprocessing.

Multiprocessing is now actual multiprocessing and not multithreading, as we discussed.
It works fine with SQL Alchemy, but I'm having trouble making it work with MySQL. I always had, so I'm
not sure this is specific to multiprocessing.
Switching to multiprocessing is the first step to using a task queue like Dramatiq or Celery, because
there is no pickling issue anymore (I'm using ID instead of actual object instances).

## Real-time update

Real-time update was causing many issues with multithreading, but it's even worse with multiprocessing.
I couldn't find a way to make it work, so I removed the database commit inside a process.
Instead, multiple processes will share a Manager.list() "log" variable when logs of all processes will be stored,
but the content of that list will only be available when the run is finished.
This means that:
- when multiprocessing is disabled, the real-time logging system still works: a window pops up and display the logs
in real-time.
- otherwise, with multiprocessing enabled, you can only see the logs at the end of the run.

The way I see it, this isn't such a big deal: having logs displayed in real-time is useful mainly for troubleshooting purposes,
when you're testing a service/workflow. When you know the service is working alright, you use multiprocessing and
you don't need real-time logs.

## From the TODO list

- multiprocessing. currently using ThreadPool, which create paramiko "broken pipe' and very high pool count outside of ien-ap and inside.
Consider switching to standard pool.
>>> Done. Next step would be to add dramatiq/celery support. That being said, I don't think multiprocessing will 
actually prevent the paramiko broken pipe issue. I've run some tests where the last message I get is "[chan 0] EOF received (0)",
and then nothing happens. I don't really see much improvement compared to multithreading... but since we needed an implementation
where args can be pickled for the future task queue implementation, this is a step in the right direction anyway.

- Ability to create a Pool given a list of devices
>>> Done in two different ways:
* There is a new endpoint in the REST API called "create_pool", you can create a pool by sending a POST request
where the payload contains the name of the pools, and two lists: devices (list of device names) and links (link names).
* From the pool management table, when you select "Edit Objects", you can now copy/paste a string with all device / link names,
separated by a comma. When these fields are not empty, eNMS will ignore what is selected in the drop-down lists.

- Add 'Type of Service' label under the 'Edit service xXxxxxxxx' Label on Steps1,2,3,4 of Service Creation Panel
>>> Done.

- propagate sub_dict variable substitution to a) header and param fields of rest_call service, and b) to other services that have dictionary_match fields
>>> Done, I think I added it everywhere where it makes sense.

- Workflow column headers are OFF and don't align
>>> Done.

- iEN-AP gui Automation/Service Mangement - "Duplicate" feature is behaving like the "Edit" feature, (i.e. the service is being modified not duplicated when "Duplicate" is used). Observed on VM 65.224.102.89, which was built on April 13, 2019, 7:51 p.m & 65.224.102.73, which was built on April 23, 2019, 5:17 p.m.
>>> Should be fixed.

- Add exception in fetch/fetch_all when on_error is specified and other cases where func method() might return None.
>>> fetch now has a new "allow_none" keyword argument that defaults to False.
In a few places where None is allowed, it is explicitly set to True.
When fetch returns None and None is not allowed, eNMS will raise an InstanceNotFoundException.
However, I didn't implement such a mechanism for fetch_all: fetch_all is always allowed to return an empty list,
there is no reason to forbid it.

- Edit/Create Workflow - email address override field is missing and should be added to match service instance panel
>>> Done.

- Import/export support for individual services and workflows: This allows engineers to send their latest workflow via email or check it into git so they are included when their VM is rebuilt. Note: Row id's should not be exposed outside of the database, i.e. should not exist in an export.
>>> Done. They are exported in the "projects/exported_jobs" folder.

- Need a programmatic “Email Helper” function/method which can be used in custom services and swiss_army_knife:
payload to send in body (might accept html format…)
recipients
subject line
option to attach a specific result
>>> Done: the function is called "send_email", you can import it and use it in your own services.
I have tested it with .txt files only, not .html, but perhaps it works too, you should try it.

- Default value for a text area not displayed
>>> Fixed.

- CREATE SERVICE AND WORKFLOW from workflow builder. Add context menu option in Workflow Builder to create new service instance.
>>> Done: the service creation is not in the context menu but a button in the workflow builder instead. Workflow creation from context menu.

- Manually selected devices in Pools get corrupted if changes are made to the indexes of the Names. Pool manual selected devices need to be stored by Device.Name. This also affects devices that are 'Selected' in Service Instances: once the indexing gets 'off' the selected devices are shifted to some other devices. (Do we need a way to remove all selected devices from service instances in case this happens??): Exported data should not contain id's. Foreign key refs should be by name
>>> The migration system now uses names instead of ID, which makes them more robust to ID shifts in the database, and also easier to understand/modify.
The problem is that your current migration files contain ID so this change is not backward compatible: I will update your migration files to switch from ID to names myself.

